{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "TRAIN_BOTTLENECK_CACHE_DIR = 'tmp/bottleneck/'\n",
    "FINAL_CACHE_DIR = 'tmp/final_bottleneck/'\n",
    "#svm_bottleneck_dir = 'svm_cache_data/bottleneck'\n",
    "#final_test_bottleneck_cache_dir = 'svm_cache_data/final_bottleneck/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_and_split_bottleneck():\n",
    "    '''\n",
    "    :Shuffled and split bottleneck from Cached directory\n",
    "    :Return shuffled bottleneck file name numpy ndarray\n",
    "    '''\n",
    "    codes = np.array([code for code in os.listdir(TRAIN_BOTTLENECK_CACHE_DIRE)])\n",
    "    labels = np.array([code[:3] for code in codes])\n",
    "    ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    train_idx, val_idx = next(ss.split(codes,labels))\n",
    "    \n",
    "    train_x, train_y = codes[train_idx], labels[train_idx]\n",
    "    val_x, val_y = codes[val_idx], labels[val_idx]\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bottleneck_value_from_file(x,y,cache_dir):\n",
    "    \"\"\"\n",
    "    : x, y are filename list of features and labels respectively\n",
    "    : return np.array\n",
    "    \"\"\"\n",
    "    bottlenecks = []\n",
    "    labels = []\n",
    "    for i in range(len(x)):\n",
    "        with open(os.path.join(cache_dir,x[i]),'r') as bottleneck_file:\n",
    "            bottlenecks.append([float(xx) for xx in bottleneck_file.read().split(',')])\n",
    "        labels.append([1 if y[i] == 'dog' else 0])\n",
    "    return np.array(bottlenecks), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, cache_dir, batch_size=batch_size): # x是bottleneck所对应的名字的一个list，如‘dog.1023.txt’；y是类别所对应的名字的list，如‘dog’\n",
    "    \"\"\"\n",
    "    : Get batches from x, y list\n",
    "    : iterable batches of feature and labels\n",
    "    \"\"\"\n",
    "    batch_num = len(x) // batch_size\n",
    "    for ii in range(0, batch_num * batch_size, batch_size):\n",
    "        if ii != (batch_num - 1) * batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size]\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        bottlenecks, labels = get_bottleneck_value_from_file(X, Y, cache_dir)\n",
    "        yield bottlenecks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_filelist_x, train_filelist_y, val_filelist_x, val_filelist_y = shuffle_and_split_bottleneck()\n",
    "    train_x, train_y = get_bottleneck_value_from_file(train_filelist_x, train_filelist_y, TRAIN_BOTTLENECK_CACHE_DIR)\n",
    "    train_y = np.squeeze(train_y)\n",
    "    clf = svm.SVC(C=0.9, kernel='rbf')\n",
    "    clf.fit(train_x, train_y)\n",
    "    \n",
    "    # validation\n",
    "    val_x, val_y = get_bottleneck_value_from_file(val_filelist_x, val_filelist_y, TRAIN_BOTTLENECK_CACHE_DIR)\n",
    "    pred = clf.predict(val_x)\n",
    "    print(pred)\n",
    "    print(val_y)\n",
    "    correct_prediction = np.equal(pred, np.squeeze(val_y))\n",
    "    accuracy = np.mean(correct_prediction.astype('float32'))\n",
    "    print('Accuracy: {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 1 0 0]\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ..., \n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
